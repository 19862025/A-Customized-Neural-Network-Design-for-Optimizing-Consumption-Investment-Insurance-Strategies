# -*- coding: utf-8 -*-
"""CII_NN_29March.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oy8S4dIA6O2Av5_i2Vod27_oeBtW0AdR
"""

# -*- coding: utf-8 -*-
"""CT_NN_23March.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JKSmDWm1FkkADE7CDATpZBDSkvoYzCtE

## Initialization
"""

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Feb 28 19:29:09 2025

@author: marcial

To do:
(1) Sensitivity analysis (MN)
* Retrain the model for Z0=0.015, 0.02,0.025,0.03
* Record the average values for c[0],b[0],rho[0]
* On the same plot, plot c[0],b[0],rho[0] as a function of Z0.
* Do the same thing for 
* sigma_Z = 0.005,0.01,0.015,0.02
* sigma_S = 0.005,0.01,0.015,0.02
* alpha_scale = 10,15,20,25

(2) Modify the code so that the user has knowledge of the current stock price, and see how that affects the performance (MN)

(3) There is a problem in the graph of the values of X. Need to look at extractPolicy2  (CT)
"""

# Fix openMP conflict error
import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Layer, Input, Dense, Concatenate, Normalization,Activation
from tensorflow.keras.callbacks import LambdaCallback
from tensorflow.keras.initializers import Constant
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from scipy.special import logit

# tf.config.run_functions_eagerly(True)

# Parameters (adjusted for balance)
J = 3200 # Number of vectors
M = 3 # Number of previous stock prices known
T = 20# Number of years (we start at year 0 and end at year T,
     # so there are T decisions)
sigma_Z = 0.01
sigma_S = 0.01
r = 0.02 # risk-free interest rate
Z0 = 0.025 # Initial random process

# Generate training data
np.random.seed(42)
B_zt = np.random.normal(0, sigma_Z, (J, T+M))
B_St = np.random.normal(0, sigma_S, (J, T+M))
B_zt[:,0] = 0
Z = Z0 + np.cumsum(B_zt, axis=-1)
Irel = Z + B_St - r

x_train = np.copy(Irel)
normalizer = Normalization()
normalizer.adapt(x_train)

y_train = np.ones((J,))# @@@ Changed because we are trying to maximize, not minimize

# Survival probabilities and discount factors
pd_t = np.linspace(0.001, 0.01, T+1)
Pbard_t = 1 - np.cumsum(pd_t)
D_t = 0.995**np.arange(T+1)
pD_t = (pd_t * D_t).reshape(1, -1)[:, :-1]
PbarD_t = (Pbard_t * D_t).reshape(1, -1)
# Need pd to multiply alpha_scale
pd_t = pd_t.reshape(1, -1)[:, :-1]
PbarD_t_tf = tf.Variable(PbarD_t, dtype=tf.float32, trainable=False)
pD_t_tf = tf.Variable(pD_t, dtype=tf.float32, trainable=False)
pd_t_tf = tf.Variable(pd_t, dtype=tf.float32, trainable=False)


# Adjusted parameters
alpha_scale = 0.9   # Mitigate bequest influence
delta = 0.5         # Consumption preference exponent
epsilon = 0.9       # Legacy preference exponent
C0, X0 = 1, 1       # Initial consumption and wealth
R = np.ones(T)      # Income @@@ Actually, this is income minus living expenses.
K = (delta/epsilon) *  X0**epsilon / C0**delta   # equlibrate consumption and legacy

utility_factor = 1/T**2 # @@@ Scale utility down in loss function to avoid saturation.

"""## Definitions"""

# %% Utility functions
def VC(C):
    C = tf.clip_by_value(C, 1e-6, 1e6)
    return tf.pow(C, delta) / delta
def VX(X):
    X = tf.clip_by_value(X, 1e-6, 1e6)
    return tf.pow(X, epsilon) / (K * epsilon)

# %% NN definitions
def tf_fn(concatenated_outputs, T,utility_factor):
    batch_size = tf.shape(concatenated_outputs)[0]

    cVals = concatenated_outputs[:, 0:4*T:4]
    bVals = concatenated_outputs[:, 1:4*T:4]
    iVals = concatenated_outputs[:, 2:4*T:4]
    rhoVals = concatenated_outputs[:, 3:4*T:4]
    IrelVals = concatenated_outputs[:, 4*T:]

    cbi_stacked = tf.stack([cVals, bVals, iVals], axis=-1)
    cbi_softmax = tf.nn.softmax(cbi_stacked, axis=-1)
    c = tf.clip_by_value(cbi_softmax[..., 0], 1e-6, 1-1e-6)  # @@@ no need to cap consumption
    b = tf.clip_by_value(cbi_softmax[..., 1], 1e-6, 1-1e-6)
    rho = tf.clip_by_value(tf.nn.sigmoid(rhoVals), 1e-6, 1-1e-6)

    x_init = tf.ones((batch_size, 1), dtype=tf.float32)

    wealth_factor = tf.clip_by_value(1 - c - b + r + rho * IrelVals, 1e-6, 1e6)

    x = tf.TensorArray(dtype=tf.float32, size=T+1, dynamic_size=False, clear_after_read=False)  # Preallocate storage
    x = x.write(0, x_init[:, 0])  # Store initial value

    for n in range(T):
        x_n = x.read(n) * wealth_factor[:, n] + R[n]  # Compute next step
        x = x.write(n + 1, x_n)  # Store result

    x = x.stack()  # Convert TensorArray to final tensor
    x = tf.transpose(x)  # Reshape to (batch_size, T+1)

    consumption_utility = VC(c*x[:,:-1]) * PbarD_t_tf[:, :-1]# @@@ changed this line
    legacy_term = x[:, :-1]  * (1 +  b / (alpha_scale * pd_t_tf + 1e-6))  # @@@ don't boost b
    legacy_utility = VX(legacy_term)* pD_t_tf
    utility = utility_factor*(consumption_utility + legacy_utility)# @@@ rescale using utility factor
    # For total utility, add utility if he survives to the end
    total_utility = tf.reduce_sum(utility, axis=1) + VX(x[:, -1]) * PbarD_t_tf[:, -1]*utility_factor# @@@
    return tf.expand_dims(total_utility, axis=-1)  # Ensure correct shape
# Custom layer to compute tf_fn
class CustomComputationLayer(Layer):
    def __init__(self, T,utility_factor, **kwargs):# @@@
        super(CustomComputationLayer, self).__init__(**kwargs)
        self.T = T
        self.utility_factor = utility_factor

    def build(self, input_shape):
        # Ensure there are no trainable parameters here
        pass

    def call(self, inputs):
        result = tf_fn(inputs, self.T,self.utility_factor)  # Ensure this returns (batch_size,)
        return result

    def compute_output_shape(self, input_shape):
       return (input_shape[0], 1)
def build_custom_model(T, M, nodeConfig,utility_factor):
    inputs = Input(shape=(T + M ,))  # Full input vector

    # Normalization Layer (only used for hidden layers, not final concatenation)
    normalized_inputs = normalizer(inputs)

    layer_outputs = []

    # Construct layers incrementally
    for tt in range(T):
        subset_input = normalized_inputs[:, :(M + tt)]  # Select first M+K inputs
        # subset_input = normalized_inputs[:, :(M + tt+1)]  # Select first M+tt inputs   @@@ This is the modified model in (2) above. We can compare this with the base model to see performance improvement. We only need to find the new mean strategies and the change in utility, we don't need to run sensitivity analysis on this model.
                                                  # (these are the previous (known) stock interest rates)

        dense = Dense(nodeConfig[tt], activation="relu")(subset_input)
        output = Dense(4, activation="linear")(dense)  # 4 output nodes @@@ Changed this
        layer_outputs.append(output)

    # Concatenate all layer outputs + original inputs
    concatenated = Concatenate()(layer_outputs + [inputs[:, M:]])

    # Pass through custom computation layer
    computed_output = CustomComputationLayer(T,utility_factor)(concatenated)# @@@

    # Apply final sigmoid activation function
    final_output = Dense(1, activation="sigmoid",use_bias=False)(computed_output)
    # Build the model
    model = Model(inputs=inputs, outputs=[final_output, layer_outputs])


    # After the model is built, manually set the weights to 1
    # Access the final Dense layer (last layer in the model)
    final_dense_layer = model.layers[-1]  # This accesses the last layer
    # Manually set the weights to 1
    final_dense_layer.set_weights([np.ones_like(final_dense_layer.get_weights()[0])])  # Set the weights to 1
    # Freeze the layer so that it doesn't get updated during training
    final_dense_layer.trainable = False

    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                  loss=["mse", None])  # No loss for layer_outputs

    return model, normalizer

# %% Other function definitions
def compute_wealth(c, b, rho, Irel,batch_size):
    x = tf.TensorArray(dtype=tf.float32, size=T + 1, dynamic_size=False,clear_after_read=False)
    x = x.write(0, tf.ones((batch_size,), dtype=tf.float32))
    for t in range(T):
        wealth_factor = 1 - c[:, t] - b[:, t] + r + rho[:, t] * Irel[:, t]
        x_t = x.read(t) * wealth_factor + R[t]
        x = x.write(t + 1, x_t)
    return tf.transpose(x.stack())
def extract_policy(concatenated_outputs, T):
    batch_size = tf.shape(concatenated_outputs)[0]

    cVals = concatenated_outputs[:, 0:4*T:4]
    bVals = concatenated_outputs[:, 1:4*T:4]
    iVals = concatenated_outputs[:, 2:4*T:4]
    rhoVals = concatenated_outputs[:, 3:4*T:4]
    IrelVals = concatenated_outputs[:, 4*T:]

    cbi_stacked = tf.stack([cVals, bVals, iVals], axis=-1)
    cbi_softmax = tf.nn.softmax(cbi_stacked, axis=-1)
    c = tf.clip_by_value(cbi_softmax[..., 0], 1e-6, 1-1e-6)# @@@ Changed
    b = tf.clip_by_value(cbi_softmax[..., 1], 1e-6, 1-1e-6)
    rho = tf.clip_by_value(tf.nn.sigmoid(rhoVals), 1e-6, 1-1e-6)

    x_init = tf.ones((batch_size,), dtype=tf.float32)
    wealth_factor = tf.clip_by_value(1 - c - b + r + rho * IrelVals, 1e-6, 1e6)

    # # Print tensor values
    # tf.print("c:", c)
    # tf.print("b:", b)
    # tf.print("rho:", rho)
    # tf.print("wealth_factor:", wealth_factor)
    # tf.print("r:", r)
    # tf.print("IrelVals:", IrelVals)

    x = tf.TensorArray(dtype=tf.float32, size=T+1,clear_after_read=False)
    x = x.write(0, x_init)
    for n in range(T):
        x_n = x.read(n) * wealth_factor[:, n] + R[n]
        x = x.write(n + 1, x_n)

    x = tf.transpose(x.stack())
    return c, b, rho, x
def extract_policy2(concatenated_outputs, T):# @@@ Why is this different from the other?
    batch_size = tf.shape(concatenated_outputs)[0]
    cVals = concatenated_outputs[:, 0:4 * T:4]
    bVals = concatenated_outputs[:, 1:4 * T:4]
    iVals = concatenated_outputs[:, 2:4 * T:4]
    rhoVals = concatenated_outputs[:, 3:4 * T:4]
    IrelVals = concatenated_outputs[:, 4 * T:]
    cbi_stacked = tf.stack([cVals, bVals, iVals], axis=-1)
    cbi_softmax = tf.nn.softmax(cbi_stacked, axis=-1)
    c = tf.clip_by_value(cbi_softmax[..., 0], 1e-6, 1 - 1e-6)# 
    b = tf.clip_by_value(cbi_softmax[..., 1], 1e-6, 1 - 1e-6)#
    rho = tf.nn.sigmoid(rhoVals)
    x_init = tf.ones((batch_size, 1), dtype=tf.float32)

    # Explicitly broadcast r to match the shape of c and b
    r_broadcasted = tf.broadcast_to(tf.constant(r, dtype=tf.float32), tf.shape(c))

    # Reshape rho to have an extra dimension of size 1 if needed
    #if rho.shape.ndims == 2:
    #    rho = tf.expand_dims(rho, -1)

    # Change how wealth factor is calculated, ensuring correct broadcasting
    wealth_factor = tf.clip_by_value(
        1 - c - b + r_broadcasted + rho*IrelVals,
        1e-6,
        1e6,
    )

    x = tf.TensorArray(
        dtype=tf.float32, size=T + 1, dynamic_size=False, clear_after_read=False
    )  # Preallocate storage
    x = x.write(0, x_init[:, 0])  # Store initial value

    for n in range(T):
        x_n = x.read(n) * wealth_factor[:, n] + R[n]  # Compute next step
        x = x.write(n + 1, x_n)  # Store result
    x = x.stack()  # Convert TensorArray to final tensor
    x = tf.transpose(x)  # Reshape to (batch_size, T + 1)

    return c.numpy(), b.numpy(), rho.numpy(), x.numpy()
def get_baseline_strategies(x_train, T, R, r, M):
    batch_size = x_train.shape[0]

    constant_c = tf.ones((batch_size, T)) * 0.5
    constant_b = tf.ones((batch_size, T)) * 0.05 # 5% goes to insurance
    constant_i = tf.ones((batch_size, T)) * 0.45
    constant_rho = tf.ones((batch_size, T)) * 0.5

    cons_c = tf.ones((batch_size, T)) * 0.2
    cons_b = tf.ones((batch_size, T)) * 0.1
    cons_i = tf.ones((batch_size, T)) * 0.7
    cons_rho = tf.ones((batch_size, T)) * 0.0

    baselines = [
        (constant_c, constant_b, constant_i, constant_rho, "Constant Allocation"),
        (cons_c, cons_b, cons_i, cons_rho, "Conservative")
    ]

    results = {}
    for c, b, i,rho, name in baselines:
        
        # Stack them into shape (batch_size, T, 4)
        stacked = tf.stack([c, b, i, rho], axis=2)
        
        # Reshape to (batch_size, 4*T) to interleave
        interleaved_inputs = tf.reshape(stacked, (tf.shape(c)[0], -1))
        concatenated_inputs = tf.concat([interleaved_inputs, x_train[:, M:]], axis=1)
        utility = tf.reduce_mean(tf_fn(concatenated_inputs, T,utility_factor))# @@@
        results[name] = float(utility/utility_factor)# @@@

    return results
def architecture_experiment(x_train, T, M, utility_factor,architectures, epochs=20):
    results = {}

    for arch_name, node_config in architectures.items():
        # Build model with this architecture
        model, _ = build_custom_model(T, M, node_config,utility_factor)

         # Dynamic dummy outputs based on the number of layers in the model, which is T
        dummy_layer_outputs = [tf.zeros((x_train.shape[0], 4)) for _ in range(T)]  # Changed to T


        # Debug: Check output shapes
        pred, layer_out = model.predict(x_train[:1])
        
        '''
        print(f"Architecture: {arch_name}")
        print("Predicted final_output shape:", pred.shape)
        print("Predicted layer_outputs length:", len(layer_out))
        print("Predicted layer_outputs shapes:", [x.shape for x in layer_out])
        print("y_train shape:", y_train.shape)
        print("dummy_layer_outputs length:", len(dummy_layer_outputs))
        print("dummy_layer_outputs shapes:", [x.shape for x in dummy_layer_outputs])
        '''

        # Train
        history = model.fit(
            x_train,
            [y_train, dummy_layer_outputs],
            epochs=epochs,
            batch_size=32,
            verbose=0
        )

        # Evaluate
        predictions, _ = model.predict(x_train)
        mean_utility = float(np.mean(logit(predictions))) / utility_factor

        predictions, _ = model.predict(x_train)
        mean_utility = float(tf.reduce_mean(predictions))/utility_factor# Correct output for utility factor
        param_count = model.count_params()

        results[arch_name] = {
            'utility': mean_utility,
            'params': param_count,
            'history': history.history
        }

        print(f"{arch_name}: Utility={mean_utility:.4f}, Params={param_count}")

    return results

## %% Main code
"""## Build and train model"""

# Build and train initial model
nodeParams = [15, 0]
nodeConfig = (nodeParams[0] * np.ones(T) + nodeParams[1] * np.arange(T)).astype(int)

model,normalizer = build_custom_model(T,M,nodeConfig,utility_factor)
model.summary()

history = model.fit(x_train, y_train, epochs=30, batch_size=32, verbose=0)# @@@ didn't have this.

final_output, layer_outputs = model(x_train)
concatenated_outputs = tf.keras.layers.Concatenate()(layer_outputs + [x_train[:, M:]])

c, b, rho, x = extract_policy(concatenated_outputs, T)

# Single path (first path)
nPath = 5
c_select = c[:nPath].numpy().T  # Convert to NumPy array first
b_select = b[:nPath].numpy().T  # Convert to NumPy array first
rho_select = rho[:nPath].numpy().T  # Convert to NumPy array first
x_select = x[:nPath].numpy().T  # Convert to NumPy array first

# print(x_select)

# %% debugging routines
# layer_outputs = [layer.output for layer in model.layers]
# debug_model = tf.keras.Model(inputs=model.input,outputs=layer_outputs)
# debug_layer_outputs =debug_model.predict(x_train[5:6,:])

# def debug_outputs(epoch, logs):
#     test_input = x_train[:1,:]  # Create a test input
#     intermediate_model = tf.keras.Model(model.input, model.get_layer(index=-2).output)  # Extract `computed_output`
#     computed_val = intermediate_model.predict(test_input)
#     print(f"Epoch {epoch}: Computed output = {computed_val}")
# debug_callback = LambdaCallback(on_epoch_end=debug_outputs)

# # Train with debug callback
# model.fit(x_train, y_train, epochs=1, callbacks=[debug_callback])

# %%

# Baseline results
baseline_results = get_baseline_strategies(x_train, T, R, r, M)
print("Baseline Results:", baseline_results)
_, layer_outputs = model(x_train)
concatenated_outputs = tf.keras.layers.Concatenate()(layer_outputs + [x_train[:, M:]])
utilities_out = tf_fn(concatenated_outputs, T,utility_factor)
mean_utility = np.mean(utilities_out.numpy())
print("Mean Utility for NN model:", mean_utility/utility_factor)

# Define architectures
architectures = {
    '5-node': 5*np.ones(T).astype(int),
    '10-node': 10*np.ones(T).astype(int),         # len=T
    '15-node': nodeConfig,       # len=T
    '20-node': 20*np.ones(T).astype(int),
    '25-node': 25*np.ones(T).astype(int)
    }

# Run experiment
arch_results = architecture_experiment(x_train, T, M, utility_factor, architectures)

# Plot architecture results
plt.figure(num=1,figsize=(10, 6))
for name, result in arch_results.items():
    plt.plot(result['history']['loss'], label=f"{name} (params: {result['params']})")
plt.legend()
plt.title("Training Loss by Architecture")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.show()

'''
# Define parameters to test
params_to_test = {
    'C0': [0.5, 0.75, 1.0, 1.25, 1.5],
    'r': [0.01, 0.015, 0.02, 0.025, 0.03],
    'sigma_S': [0.001, 0.003, 0.005, 0.007, 0.01]
}
# @@@ reduced set
params_to_test = {
    'C0': [0.75, 1.0, 1.25],
    'r': [0.015, 0.02, 0.025],
    'sigma_S': [0.003, 0.005, 0.007]
}

# @@@ this sensitivity must be redone.  The idea is that if you train with the wrong idea of r or sigma, how much performance do you lose?

# @@@ We should also train with perfect knowledge of the stock price, and see what the performance loss is.

# sensitivity_results = sensitivity_analysis(model, x_train, T, params_to_test)
# print("Sensitivity Results:", sensitivity_results)
# # # Run sensitivity analysis
'''

_, layer_outputs = model(x_train)
concatenated_outputs = tf.keras.layers.Concatenate()(layer_outputs + [x_train[:, M:]])
utilities_out = tf_fn(concatenated_outputs, T,utility_factor)
mean_utility = np.mean(utilities_out.numpy())
print("Mean Utility:", mean_utility/utility_factor)

c, b, rho, x = extract_policy2(concatenated_outputs, T)

# Plot selected paths

nPath=8
c_select = c[:nPath].T
b_select = b[:nPath].T
rho_select = rho[:nPath].T
x_select = x[:nPath].T

# Average across paths
c_mean = np.mean(c, axis=0)
b_mean = np.mean(b, axis=0)
rho_mean = np.mean(rho, axis=0)
x_mean = np.mean(x, axis=0)

# Debug Irel
print("Irel mean:", np.mean(Irel[:, 1:]), "Irel std:", np.std(Irel[:, 1:]))

# Visualize paths
plt.figure(num=2,figsize=(12, 8))
plt.subplot(2, 2, 1)
plt.plot(range(T), c_select, label='Consumption (c)', marker='o')
plt.title('Consumption, selected paths')
plt.xlabel('Time Step')
plt.ylabel('c')

plt.subplot(2, 2, 2)
plt.plot(range(T), b_select, label='Bequest (b)', marker='o', color='orange')
plt.title('Bequest, selected paths')
plt.xlabel('Time Step')
plt.ylabel('b')

plt.subplot(2, 2, 3)
plt.plot(range(T), rho_select, label='Risk Exposure (rho)', marker='o', color='green')
plt.title('Risk Exposure, selected paths')
plt.xlabel('Time Step')
plt.ylabel('rho')

plt.subplot(2, 2, 4)
plt.plot(range(T+1), x_select, label='Wealth (x)', marker='o', color='red')
plt.title('Wealth, selected paths')
plt.xlabel('Time Step')
plt.ylabel('x')

plt.suptitle(f'Parameter Evolution, alpha_scale = {alpha_scale}', fontsize=16)
plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to make room for suptitle
plt.show()

# Print results
print("Average c:", c_mean)
print("Average b:", b_mean)
print("Average rho:", rho_mean)
print("Average x:", x_mean)